{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KravitzLab/Murrell2025/blob/main/Murrell_2026_Fig3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Murrell 2026 Figure 3\n",
        "<br>\n",
        "<img src=\"https://fed3bandit.readthedocs.io/en/latest/_static/fed3bandit_logo1.svg\" width=\"200\" />\n",
        "\n",
        "Bandit 80_20\n",
        "Metrics of performance in trained mice (last 24 hours)  \n",
        "Authors: Chantelle Murrell<br>\n",
        "Updated: 12-30-25  "
      ],
      "metadata": {
        "id": "ru9_Mj2OpjhT"
      },
      "id": "ru9_Mj2OpjhT"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install libraries and import them {\"run\":\"auto\"}\n",
        "\n",
        "import importlib.util\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Packages to ensure are installed (add others here if you like)\n",
        "packages = {\n",
        "    \"fed3\": \"git+https://github.com/earnestt1234/fed3.git\",\n",
        "    \"fed3bandit\": \"fed3bandit\",\n",
        "    \"pingouin\": \"pingouin\",\n",
        "    \"ipydatagrid\": \"ipydatagrid\",\n",
        "    \"openpyxl\": \"openpyxl\",\n",
        "}\n",
        "\n",
        "for name, source in packages.items():\n",
        "    if importlib.util.find_spec(name) is None:\n",
        "        print(f\"Installing {name}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", source])\n",
        "\n",
        "# ----------------------------\n",
        "# Imports\n",
        "# ----------------------------\n",
        "# Standard library\n",
        "import copy\n",
        "import io\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import tempfile\n",
        "import threading\n",
        "import time\n",
        "import warnings\n",
        "import zipfile\n",
        "import requests\n",
        "import glob\n",
        "from datetime import datetime, timedelta\n",
        "from os.path import basename, splitext\n",
        "\n",
        "# Third-party\n",
        "from ipydatagrid import DataGrid, TextRenderer\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pingouin as pg\n",
        "import fed3\n",
        "import fed3.plot as fplot\n",
        "import fed3bandit as f3b\n",
        "from scipy.stats import f_oneway\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "from google.colab import files\n",
        "try:\n",
        "    from tqdm.auto import tqdm   # nice in notebooks; falls back to std tqdm on console\n",
        "except Exception:\n",
        "    # safe no-op fallback if tqdm isn't installed\n",
        "    def tqdm(x):\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Configuration\n",
        "# ----------------------------\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.rcParams.update({'font.size': 12, 'figure.autolayout': True})\n",
        "plt.rcParams['figure.figsize'] = [6, 4]\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['axes.spines.top'] = False\n",
        "plt.rcParams['axes.spines.right'] = False\n",
        "\n",
        "print(\"Packages installed and imports ready.\")\n"
      ],
      "metadata": {
        "id": "c_vNg7dvVfCh",
        "cellView": "form",
        "collapsed": true
      },
      "id": "c_vNg7dvVfCh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import FED3 Bandit 80-20 data\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "import os, zipfile, shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    from google.colab import output as colab_output\n",
        "    colab_output.enable_custom_widget_manager()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "zip_url = \"https://github.com/KravitzLab/Murrell2025/raw/refs/heads/main/Data/Bandit80.zip\"\n",
        "key_url = \"https://github.com/KravitzLab/Murrell2025/raw/refs/heads/main/Data/Murrell2026_Key.csv\"\n",
        "\n",
        "zip_dir = \"/content/Murrell2025_zipdata\"\n",
        "zip_path = os.path.join(zip_dir, \"Bandit80.zip\")\n",
        "extract_root = os.path.join(zip_dir, \"Bandit80_extracted\")\n",
        "key_path = os.path.join(zip_dir, \"Murrell2026_Key.csv\")\n",
        "\n",
        "os.makedirs(zip_dir, exist_ok=True)\n",
        "\n",
        "# download + unzip (fresh each run)\n",
        "if os.path.exists(zip_path):\n",
        "    os.remove(zip_path)\n",
        "if os.path.isdir(extract_root):\n",
        "    shutil.rmtree(extract_root)\n",
        "\n",
        "print(\"Importing github.com/KravitzLab/Murrell2025/Data/Bandit80.zip ...\")\n",
        "urlretrieve(zip_url, zip_path)\n",
        "\n",
        "os.makedirs(extract_root, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "    zf.extractall(extract_root)\n",
        "\n",
        "# if the zip contains a Bandit80 folder, use it; otherwise use extract_root\n",
        "bandit_root = os.path.join(extract_root, \"Bandit80\")\n",
        "local_parent_path = bandit_root if os.path.isdir(bandit_root) else extract_root\n",
        "\n",
        "# load CSVs\n",
        "feds, loaded_files, session_types = [], [], []\n",
        "\n",
        "for dirpath, _, filenames in os.walk(local_parent_path):\n",
        "    for file_name in sorted(filenames):\n",
        "        if file_name.lower().endswith(\".csv\"):\n",
        "            file_path = os.path.join(dirpath, file_name)\n",
        "            strain_name = os.path.basename(os.path.dirname(file_path))\n",
        "\n",
        "            df = fed3.load(file_path)\n",
        "            df.name = file_name\n",
        "            df[\"Strain\"] = strain_name\n",
        "            df[\"SourceFile\"] = file_name\n",
        "\n",
        "            feds.append(df)\n",
        "            loaded_files.append(file_path)\n",
        "\n",
        "            st = df[\"Session_Type\"].dropna().astype(str)\n",
        "            session_types.append(st.iloc[0] if len(st) else None)\n",
        "\n",
        "print(f\"Loaded {len(feds)} CSV files.\")\n",
        "\n",
        "# download + load key\n",
        "urlretrieve(key_url, key_path)\n",
        "\n",
        "key_df = pd.read_csv(key_path, encoding=\"utf-8-sig\")\n",
        "key_df[\"Mouse_ID\"] = key_df[\"Mouse_ID\"].astype(str).str.strip()\n",
        "\n",
        "# match Mouse_ID by substring in filename base\n",
        "def _base_lower(p):\n",
        "    return os.path.splitext(os.path.basename(p))[0].lower()\n",
        "\n",
        "files_df = pd.DataFrame({\"filename\": loaded_files, \"Session_type\": session_types})\n",
        "files_df[\"_base\"] = files_df[\"filename\"].map(_base_lower)\n",
        "\n",
        "mouse_ids = (\n",
        "    key_df[\"Mouse_ID\"]\n",
        "    .dropna().astype(str).str.strip()\n",
        "    .replace(\"\", np.nan).dropna().unique().tolist()\n",
        ")\n",
        "\n",
        "rows = []\n",
        "for fname, base in zip(files_df[\"filename\"], files_df[\"_base\"]):\n",
        "    hits = [mid for mid in mouse_ids if mid.lower() in base]\n",
        "    rows.append({\"filename\": fname, \"Mouse_ID\": hits[0] if len(hits) else None})\n",
        "\n",
        "matched = pd.DataFrame(rows)\n",
        "\n",
        "Key_Df = (\n",
        "    files_df.drop(columns=[\"_base\"])\n",
        "    .merge(matched, on=\"filename\", how=\"left\")\n",
        "    .merge(key_df.drop_duplicates(\"Mouse_ID\"), on=\"Mouse_ID\", how=\"left\")\n",
        ")\n",
        "\n",
        "# display\n",
        "grid = DataGrid(\n",
        "    Key_Df.reset_index(drop=True),\n",
        "    editable=True,\n",
        "    selection_mode=\"cell\",\n",
        "    layout={\"height\": \"420px\"},\n",
        "    base_row_size=28,\n",
        "    base_column_size=120,\n",
        ")\n",
        "grid.default_renderer = TextRenderer(text_wrap=True)\n",
        "display(grid)"
      ],
      "metadata": {
        "id": "_3hqwt-oejwc",
        "cellView": "form"
      },
      "id": "_3hqwt-oejwc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot individual files (males blue females red)\n",
        "# ----- Inputs -----\n",
        "assert 'feds' in globals() and isinstance(feds, list) and len(feds) > 0, \"No FED3 files loaded.\"\n",
        "assert 'Key_Df' in globals() and isinstance(Key_Df, pd.DataFrame), \"Build/rematch Key_Df first.\"\n",
        "\n",
        "TIMESTAMP_COL_CANON = \"MM:DD:YYYY hh:mm:ss\"  # primary target column name\n",
        "\n",
        "# ----- Helpers -----\n",
        "def _find_time_col(df):\n",
        "    # exact match first\n",
        "    if TIMESTAMP_COL_CANON in df.columns:\n",
        "        return TIMESTAMP_COL_CANON\n",
        "    # tolerant search (case/space-insensitive)\n",
        "    lc = {str(c).strip().lower(): c for c in df.columns}\n",
        "    for key in lc:\n",
        "        if key.replace(\" \", \"\") in {\"mm:dd:yyyyhh:mm:ss\", \"mm:dd:yyyy_hh:mm:ss\", \"mm/dd/yyyyhh:mm:ss\"}:\n",
        "            return lc[key]\n",
        "    return None\n",
        "\n",
        "def _parse_ts(series):\n",
        "    # robust parsing; coerce errors to NaT\n",
        "    return pd.to_datetime(series, errors=\"coerce\", infer_datetime_format=True)\n",
        "\n",
        "\n",
        "# ----- Plotting\n",
        "files_list = feds\n",
        "\n",
        "# metadata_df = copy of Key_Df\n",
        "metadata_df = Key_Df.copy().reset_index(drop=True)\n",
        "if 'filename' in metadata_df.columns:\n",
        "    metadata_df['filename'] = metadata_df['filename'].astype(str).map(os.path.basename)\n",
        "\n",
        "def _coerce_numeric_col(df, col, clip_upper=None, na_map=None):\n",
        "    if col not in df.columns:\n",
        "        return\n",
        "    s = df[col]\n",
        "    if na_map:\n",
        "        s = s.replace(na_map)\n",
        "    s = pd.to_numeric(s, errors='coerce')\n",
        "    if clip_upper is not None:\n",
        "        s.loc[s > clip_upper] = np.nan\n",
        "    df[col] = s\n",
        "\n",
        "def _plot_file_core(file_index):\n",
        "    df = files_list[file_index].copy()\n",
        "    full_name = getattr(df, 'name', f\"File_{file_index}\")\n",
        "    file_basename = os.path.basename(str(full_name))\n",
        "\n",
        "    # Preserve original index once\n",
        "    if \"Original_Timestamp\" not in df.columns:\n",
        "        df[\"Original_Timestamp\"] = df.index\n",
        "\n",
        "    # Attach metadata by filename (matching already done upstream)\n",
        "    meta_row = None\n",
        "    if 'filename' in metadata_df.columns:\n",
        "        mr = metadata_df.loc[metadata_df['filename'] == file_basename]\n",
        "        if not mr.empty:\n",
        "            meta_row = mr.iloc[0]\n",
        "    if meta_row is not None:\n",
        "        for col in meta_row.index:\n",
        "            if col == 'filename':\n",
        "                continue\n",
        "            if col not in df.columns:\n",
        "                df[col] = meta_row[col]\n",
        "            else:\n",
        "                if pd.isna(df[col]).all() and pd.notna(meta_row[col]):\n",
        "                    df[col] = meta_row[col]\n",
        "\n",
        "    # Time + cleanup\n",
        "    try:\n",
        "        df['timestamp'] = pd.to_datetime(df.index)\n",
        "    except Exception:\n",
        "        df['timestamp'] = np.arange(len(df))\n",
        "\n",
        "    _coerce_numeric_col(df, 'Poke_Time', clip_upper=2)\n",
        "    _coerce_numeric_col(df, 'Retrieval_Time', na_map={\"Timed_out\": np.nan})\n",
        "\n",
        "    if len(df) == 0:\n",
        "        print(f\"[!] Empty cropped dataframe for {file_basename}. Skipping plot.\")\n",
        "        return\n",
        "\n",
        "    # Behavioral traces (needs f3b)\n",
        "    true_left = f3b.true_probs(df, offset=5)[0]\n",
        "    mouse_left = f3b.binned_paction(df, window=10)\n",
        "\n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(7, 3))\n",
        "    ax.plot(np.arange(len(true_left)), true_left, color=\"black\", linewidth=2, alpha=0.5)\n",
        "\n",
        "    color = \"dodgerblue\"\n",
        "    if 'Sex' in df.columns and pd.notna(df['Sex']).any():\n",
        "        try:\n",
        "            color = \"red\" if str(df['Sex'].iloc[0]).strip().lower().startswith(\"f\") else \"dodgerblue\"\n",
        "        except Exception:\n",
        "            pass\n",
        "    ax.plot(np.arange(len(mouse_left)), mouse_left, color=color, linewidth=3, alpha=0.7)\n",
        "\n",
        "    # ---- Clean look: remove ticks, labels, spines ----\n",
        "    ax.set_xlabel(\"\")                 # no x label\n",
        "    ax.set_ylabel(\"\")                 # no y label\n",
        "    ax.tick_params(axis=\"both\", which=\"both\",\n",
        "                   bottom=False, top=False, left=False, right=False,\n",
        "                   labelbottom=False, labelleft=False)\n",
        "    for s in ax.spines.values():      # remove axis lines\n",
        "        s.set_visible(False)\n",
        "\n",
        "    # ---- Textual y \"labels\" at y=1 and y=0 (not ticks) ----\n",
        "    ax.text(-0.01, 1.0, \"Right\", transform=ax.get_yaxis_transform(),\n",
        "            ha=\"right\", va=\"center\")\n",
        "    ax.text(-0.01, 0.0, \"Left\",  transform=ax.get_yaxis_transform(),\n",
        "            ha=\"right\", va=\"center\")\n",
        "\n",
        "    # ---- Title-area arrow above the axes ----\n",
        "    # spans full width; adjust y (1.08–1.15) if you need more/less space\n",
        "    ax.annotate(\"\",\n",
        "                xy=(0.95, 1.05), xytext=(0.05, 1.05),\n",
        "                xycoords=\"axes fraction\",\n",
        "                arrowprops=dict(arrowstyle=\"->\", lw=5, color=\"0.6\"))\n",
        "    # Optional: small caption above the arrow (example: duration text)\n",
        "    ax.text(0.4, 1.15, \"2 days\", transform=ax.transAxes, ha=\"left\", va=\"bottom\", color=\"0.5\")\n",
        "    sns.despine(left=True, bottom=True, top=True, right=True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ----- Simple UI: slider + status + output -----\n",
        "N = len(files_list)\n",
        "assert N > 0, \"No files available after cropping.\"\n",
        "idx_slider = widgets.IntSlider(min=0, max=max(0, N-1), step=1, value=0, description='File', continuous_update=True)\n",
        "status_lbl = widgets.HTML()\n",
        "out = widgets.Output()\n",
        "\n",
        "def _status(idx):\n",
        "    name = getattr(files_list[idx], 'name', f\"File_{idx}\")\n",
        "    return f\"Index: <b>{idx}</b> &nbsp;|&nbsp; File: <code>{os.path.basename(str(name))}</code> &nbsp;|&nbsp; Rows: {len(files_list[idx])}\"\n",
        "\n",
        "def _render(*_):\n",
        "    idx = int(idx_slider.value)\n",
        "    status_lbl.value = _status(idx)\n",
        "    out.clear_output()\n",
        "    with out:\n",
        "        _plot_file_core(idx)\n",
        "\n",
        "idx_slider.observe(_render, names='value')\n",
        "display(widgets.VBox([idx_slider, status_lbl, out]))\n",
        "_render()\n"
      ],
      "metadata": {
        "id": "qeZfA9tXWngI",
        "cellView": "form"
      },
      "id": "qeZfA9tXWngI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Analyze Bandit metrics\n",
        "\n",
        "def _find_time_col(df):\n",
        "    for c in [\"MM:DD:YYYY hh:mm:ss\", \"DateTime\", \"Datetime\", \"Timestamp\", \"timestamp\", \"datetime\"]:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def _get_timestamp_series(df, ts_col=\"MM:DD:YYYY hh:mm:ss\"):\n",
        "    import pandas as pd\n",
        "    if ts_col in df.columns:\n",
        "        ts = pd.to_datetime(df[ts_col], format=\"%m:%d:%Y %H:%M:%S\", errors=\"coerce\")\n",
        "        return pd.Series(ts, index=df.index)\n",
        "    for cand in [\"DateTime\", \"Datetime\", \"Timestamp\", \"timestamp\", \"datetime\"]:\n",
        "        if cand in df.columns:\n",
        "            ts = pd.to_datetime(df[cand], errors=\"coerce\")\n",
        "            return pd.Series(ts, index=df.index)\n",
        "    idx = df.index\n",
        "    if isinstance(idx, pd.DatetimeIndex):\n",
        "        return pd.Series(idx, index=df.index)\n",
        "    return pd.to_datetime(pd.Series(idx, index=df.index), errors=\"coerce\")\n",
        "\n",
        "def _crop_last_24h(df):\n",
        "    import pandas as pd\n",
        "    dfc = df.copy()\n",
        "    ts_col = _find_time_col(dfc)\n",
        "\n",
        "    if ts_col is not None:\n",
        "        ts_series = pd.to_datetime(dfc[ts_col], errors=\"coerce\", infer_datetime_format=True)\n",
        "        ts_series = pd.Series(ts_series, index=dfc.index)\n",
        "    else:\n",
        "        try:\n",
        "            ts_idx = pd.to_datetime(dfc.index, errors=\"coerce\", infer_datetime_format=True)\n",
        "            ts_series = pd.Series(ts_idx, index=dfc.index)\n",
        "        except Exception:\n",
        "            return df  # no usable timestamps → return original\n",
        "\n",
        "    if ts_series.isna().all():\n",
        "        return df\n",
        "\n",
        "    end = ts_series.max()\n",
        "    if pd.isna(end):\n",
        "        return df\n",
        "    start = end - pd.Timedelta(hours=24)\n",
        "\n",
        "    mask = ts_series.between(start, end, inclusive=\"both\")\n",
        "    cropped = dfc.loc[mask]\n",
        "\n",
        "    if hasattr(df, \"name\"):\n",
        "        cropped.name = df.name\n",
        "    return cropped\n",
        "\n",
        "def build_feds_cropped(sessions):\n",
        "    \"\"\"Return a list of sessions cropped to their last 24h.\"\"\"\n",
        "    return [_crop_last_24h(d) for d in sessions]\n",
        "\n",
        "# Use it like this:\n",
        "assert 'feds' in globals() and isinstance(feds, (list, tuple)) and len(feds) > 0, \"No FED3 files available.\"\n",
        "feds_cropped = build_feds_cropped(feds)\n",
        "\n",
        "# Prefer cropped sessions downstream\n",
        "_sessions = list(feds_cropped) if len(feds_cropped) > 0 else list(feds)\n",
        "# ----- Build feds_cropped -----\n",
        "feds_cropped = [_crop_last_24h(d) for d in feds]\n",
        "# ---------- Inputs ----------\n",
        "# Prefer cropped sessions\n",
        "if 'feds_cropped' in globals() and isinstance(feds_cropped, (list, tuple)) and len(feds_cropped) > 0:\n",
        "    _sessions = list(feds_cropped)\n",
        "else:\n",
        "    assert 'feds' in globals() and isinstance(feds, (list, tuple)) and len(feds) > 0, \"No FED3 files available.\"\n",
        "    _sessions = list(feds)\n",
        "\n",
        "# metadata_df from Key_Df\n",
        "if 'metadata_df' not in globals() or not isinstance(metadata_df, pd.DataFrame):\n",
        "    assert 'Key_Df' in globals() and isinstance(Key_Df, pd.DataFrame), \"Build/rematch Key_Df first.\"\n",
        "    metadata_df = Key_Df.copy().reset_index(drop=True)\n",
        "\n",
        "def _basename(pathlike) -> str:\n",
        "    s = str(pathlike).replace(\"\\\\\", \"/\")\n",
        "    return s.split(\"/\")[-1]\n",
        "\n",
        "def _get_timestamp_series(df, ts_col=\"MM:DD:YYYY hh:mm:ss\"):\n",
        "    if ts_col in df.columns:\n",
        "        ts = pd.to_datetime(df[ts_col], format=\"%m:%d:%Y %H:%M:%S\", errors=\"coerce\")\n",
        "        return pd.Series(ts, index=df.index)\n",
        "    for cand in [\"DateTime\", \"Datetime\", \"Timestamp\", \"timestamp\", \"datetime\"]:\n",
        "        if cand in df.columns:\n",
        "            ts = pd.to_datetime(df[cand], errors=\"coerce\")\n",
        "            return pd.Series(ts, index=df.index)\n",
        "    idx = df.index\n",
        "    if isinstance(idx, pd.DatetimeIndex):\n",
        "        return pd.Series(idx, index=df.index)\n",
        "    return pd.to_datetime(pd.Series(idx, index=df.index), errors=\"coerce\")\n",
        "\n",
        "def _split_day_night(df, ts_col=\"MM:DD:YYYY hh:mm:ss\"):\n",
        "    ts = _get_timestamp_series(df, ts_col=ts_col)\n",
        "    valid = ts.notna()\n",
        "    hrs = ts.dt.hour\n",
        "    day_mask = valid & (hrs >= 7) & (hrs < 19)\n",
        "    night_mask = valid & ~day_mask\n",
        "    return df.loc[day_mask], df.loc[night_mask]\n",
        "\n",
        "def compute_withinbout_lose_shift(c_df, max_gap_s=120):\n",
        "    try:\n",
        "        if \"Event\" not in c_df.columns or len(c_df) < 2:\n",
        "            return np.nan\n",
        "        events = c_df[\"Event\"].to_numpy()\n",
        "        times = _get_timestamp_series(c_df).to_numpy()\n",
        "        total = shifted = 0\n",
        "        for i in range(len(events) - 1):\n",
        "            curr_evt, next_evt = events[i], events[i + 1]\n",
        "            if curr_evt not in (\"Left\", \"Right\"):\n",
        "                continue\n",
        "            dt_s = (times[i + 1] - times[i]) / np.timedelta64(1, \"s\")\n",
        "            if np.isnan(dt_s) or dt_s > max_gap_s:\n",
        "                continue\n",
        "            if next_evt == \"Pellet\":\n",
        "                continue\n",
        "            if next_evt in (\"Left\", \"Right\"):\n",
        "                total += 1\n",
        "                if next_evt != curr_evt:\n",
        "                    shifted += 1\n",
        "        return (shifted / total) if total > 0 else np.nan\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def compute_withinbout_win_stay(c_df, max_gap_s=120):\n",
        "    try:\n",
        "        if \"Event\" not in c_df.columns or len(c_df) < 3:\n",
        "            return np.nan\n",
        "        events = c_df[\"Event\"].to_numpy()\n",
        "        times = _get_timestamp_series(c_df).to_numpy()\n",
        "        pellet_idx = [i for i in range(1, len(events) - 1) if events[i] == \"Pellet\"]\n",
        "        total = same = 0\n",
        "        for i in pellet_idx:\n",
        "            prev_event, next_event = events[i - 1], events[i + 1]\n",
        "            dt_s = (times[i + 1] - times[i]) / np.timedelta64(1, \"s\")\n",
        "            if not np.isnan(dt_s) and dt_s <= max_gap_s:\n",
        "                if prev_event in (\"Left\", \"Right\") and next_event in (\"Left\", \"Right\"):\n",
        "                    total += 1\n",
        "                    if next_event == prev_event:\n",
        "                        same += 1\n",
        "        return (same / total) if total > 0 else np.nan\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def compute_peak_accuracy(c_df):\n",
        "    try:\n",
        "        rev_avg = f3b.reversal_peh(c_df, (-10, 10), True)\n",
        "        if len(rev_avg) == 0:\n",
        "            return np.nan\n",
        "        return float(np.mean(rev_avg[:10])) if len(rev_avg) >= 10 else float(np.mean(rev_avg))\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def estimate_daily_pellets(c_df):\n",
        "    ts = _get_timestamp_series(c_df)\n",
        "    valid_ts = ts.dropna()\n",
        "    if valid_ts.size < 2:\n",
        "        return np.nan\n",
        "    duration_hours = (valid_ts.max() - valid_ts.min()).total_seconds() / 3600.0\n",
        "    if duration_hours <= 0:\n",
        "        return np.nan\n",
        "\n",
        "    pellet_events = np.nan\n",
        "    if \"Pellet_Count\" in c_df.columns and c_df[\"Pellet_Count\"].notna().any():\n",
        "        pc = pd.to_numeric(c_df[\"Pellet_Count\"], errors=\"coerce\")\n",
        "        if pc.notna().any():\n",
        "            diffs = pc.diff().fillna(0).clip(lower=0)\n",
        "            pellet_events = float(diffs.sum())\n",
        "            if pellet_events == 0 and pc.iloc[-1] >= pc.iloc[0]:\n",
        "                pellet_events = float(pc.iloc[-1] - pc.iloc[0])\n",
        "    if (pd.isna(pellet_events)) and (\"Event\" in c_df.columns):\n",
        "        pellet_events = float((c_df[\"Event\"] == \"Pellet\").sum())\n",
        "\n",
        "    if pd.isna(pellet_events):\n",
        "        return np.nan\n",
        "    return (pellet_events / duration_hours) * 24.0\n",
        "\n",
        "# ---------- Prepare metadata (merge once by filename) ----------\n",
        "md = metadata_df.copy()\n",
        "md['filename'] = md['filename'].astype(str).map(_basename)\n",
        "if 'Mouse_ID' in md.columns:\n",
        "    md['Mouse_ID'] = md['Mouse_ID'].astype(str).str.strip()\n",
        "else:\n",
        "    md['Mouse_ID'] = np.nan\n",
        "\n",
        "# Keep only metadata columns we care about; rename to avoid accidental dupes\n",
        "# (add/remove columns as needed)\n",
        "meta_keep = [c for c in md.columns if c in {\"filename\", \"Mouse_ID\", \"Session_type\", \"Cohort\", \"Strain\", \"Sex\"}]\n",
        "md_clean = md[meta_keep].drop_duplicates(subset=[\"filename\"], keep=\"first\")\n",
        "\n",
        "# ---------- Compute metrics on the chosen sessions ----------\n",
        "rows = []\n",
        "for idx in tqdm(range(len(_sessions))):\n",
        "    c_df = _sessions[idx]\n",
        "    file_name = _basename(getattr(c_df, \"name\", f\"File_{idx}\"))\n",
        "\n",
        "    try:\n",
        "        clean_retrieval_time = pd.to_numeric(c_df.get(\"Retrieval_Time\", pd.Series(dtype=float)), errors=\"coerce\")\n",
        "        clean_poke_time = pd.to_numeric(c_df.get(\"Poke_Time\", pd.Series(dtype=float)), errors=\"coerce\")\n",
        "        clean_poke_time = clean_poke_time[clean_poke_time > 0]\n",
        "\n",
        "        day_df, night_df = _split_day_night(c_df, ts_col=\"MM:DD:YYYY hh:mm:ss\")\n",
        "\n",
        "        row = {\n",
        "            \"filename\": file_name,\n",
        "            \"PeakAccuracy\": compute_peak_accuracy(c_df),\n",
        "            \"Total_pellets\": f3b.count_pellets(c_df),\n",
        "            \"Total_pokes\": f3b.count_pokes(c_df),\n",
        "            \"PokesPerPellet\": f3b.pokes_per_pellet(c_df),\n",
        "            \"RetrievalTime\": clean_retrieval_time.median() if not clean_retrieval_time.empty else np.nan,\n",
        "            \"PokeTime\": clean_poke_time.median() if not clean_poke_time.empty else np.nan,\n",
        "            \"Win-stay\": compute_withinbout_win_stay(c_df),\n",
        "            \"Lose-shift\": compute_withinbout_lose_shift(c_df),\n",
        "            \"daily pellets\": estimate_daily_pellets(c_df),\n",
        "            \"PeakAccuracy_Day\": compute_peak_accuracy(day_df),\n",
        "            \"PeakAccuracy_Night\": compute_peak_accuracy(night_df),\n",
        "            \"Win-stay_Day\": compute_withinbout_win_stay(day_df),\n",
        "            \"Win-stay_Night\": compute_withinbout_win_stay(night_df),\n",
        "            \"Lose-shift_Day\": compute_withinbout_lose_shift(day_df),\n",
        "            \"Lose-shift_Night\": compute_withinbout_lose_shift(night_df),\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed on {file_name} (idx {idx}): {e}\")\n",
        "\n",
        "Bandit80_metrics = pd.DataFrame(rows)\n",
        "Bandit80_metrics = Bandit80_metrics.merge(md_clean, on=\"filename\", how=\"left\")\n",
        "Bandit80_metrics = Bandit80_metrics.loc[:, ~Bandit80_metrics.columns.duplicated()]\n",
        "csv_name = \"Bandit80_metrics.csv\"\n",
        "Bandit80_metrics.to_csv(csv_name, index=False)\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "def download_csv(b):\n",
        "    files.download(csv_name)\n",
        "\n",
        "download_button = widgets.Button(\n",
        "    description=\"⬇️ Download summary stats (CSV)\",\n",
        "    button_style=\"primary\",\n",
        ")\n",
        "\n",
        "download_button.on_click(download_csv)\n",
        "display(download_button)"
      ],
      "metadata": {
        "id": "gTvKLp-fXgZk",
        "collapsed": true,
        "cellView": "form"
      },
      "id": "gTvKLp-fXgZk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Female vs Male\n",
        "\n",
        "import os, time, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "try:\n",
        "    from google.colab import files as colab_files\n",
        "except Exception:\n",
        "    colab_files = None\n",
        "\n",
        "# -----------------------\n",
        "# Config\n",
        "# -----------------------\n",
        "GROUP_COL = \"Sex\"\n",
        "metrics = [\n",
        "    \"daily pellets\", \"Total_pokes\", \"PokesPerPellet\", \"PokeTime\",\n",
        "    \"PeakAccuracy\", \"Win-stay\", \"Lose-shift\", \"RetrievalTime\",\n",
        "]\n",
        "COLOR_MAP = {\"F\": \"red\", \"M\": \"dodgerblue\"}\n",
        "\n",
        "# -----------------------\n",
        "# Preconditions\n",
        "# -----------------------\n",
        "if \"Bandit80_metrics\" not in globals() or Bandit80_metrics is None or Bandit80_metrics.empty:\n",
        "    raise RuntimeError(\"Bandit80_metrics is missing/empty. Run the metrics cell first.\")\n",
        "\n",
        "bm = Bandit80_metrics.copy()\n",
        "\n",
        "# -----------------------\n",
        "# Helper: normalize Sex to F/M/UNK\n",
        "# -----------------------\n",
        "def _norm_sex(x):\n",
        "    s = str(x).strip().upper()\n",
        "    if s in {\"F\", \"FEMALE\", \"FEM\"}: return \"F\"\n",
        "    if s in {\"M\", \"MALE\"}: return \"M\"\n",
        "    return \"UNK\"\n",
        "\n",
        "# -----------------------\n",
        "# Ensure we have Sex (merge from metadata_df if needed)\n",
        "# -----------------------\n",
        "if GROUP_COL not in bm.columns or bm[GROUP_COL].isna().all():\n",
        "\n",
        "    if \"metadata_df\" not in globals() or metadata_df is None or metadata_df.empty:\n",
        "        raise RuntimeError(\"Sex not found in Bandit80_metrics and metadata_df is missing/empty.\")\n",
        "\n",
        "    meta = metadata_df.copy()\n",
        "\n",
        "    # Normalize column names for robust lookup\n",
        "    def _find_col(df, name):\n",
        "        lc = {str(c).strip().lower(): c for c in df.columns}\n",
        "        return lc.get(name.lower(), None)\n",
        "\n",
        "    meta_sex = _find_col(meta, \"Sex\")\n",
        "    if meta_sex is None:\n",
        "        raise RuntimeError(\"metadata_df does not contain a 'Sex' column (case-insensitive).\")\n",
        "\n",
        "    # Prefer merging by Mouse_ID if present in both\n",
        "    meta_mouse = _find_col(meta, \"Mouse_ID\")\n",
        "    bm_mouse   = _find_col(bm, \"Mouse_ID\")\n",
        "\n",
        "    merged = None\n",
        "\n",
        "    if meta_mouse is not None and bm_mouse is not None:\n",
        "        meta_key = meta[[meta_mouse, meta_sex]].copy()\n",
        "        meta_key.columns = [\"Mouse_ID\", \"Sex\"]\n",
        "        meta_key[\"Mouse_ID\"] = meta_key[\"Mouse_ID\"].astype(str).str.strip()\n",
        "        meta_key = meta_key.dropna(subset=[\"Mouse_ID\"]).drop_duplicates(\"Mouse_ID\")\n",
        "\n",
        "        bm[\"Mouse_ID\"] = bm[bm_mouse].astype(str).str.strip()\n",
        "        merged = bm.merge(meta_key, on=\"Mouse_ID\", how=\"left\")\n",
        "\n",
        "    # Fallback: merge by filename basename if Mouse_ID isn’t available\n",
        "    if merged is None or merged[\"Sex\"].isna().all():\n",
        "        # build/ensure filename columns\n",
        "        if \"filename\" not in bm.columns:\n",
        "            if \"File\" in bm.columns:\n",
        "                bm[\"filename\"] = bm[\"File\"].astype(str)\n",
        "            else:\n",
        "                raise RuntimeError(\"Need either Mouse_ID or filename/File in Bandit100_metrics to merge Sex.\")\n",
        "\n",
        "        if \"filename\" not in meta.columns:\n",
        "            # if metadata_df already has filename, great; otherwise cannot fallback\n",
        "            raise RuntimeError(\"Cannot fallback merge: metadata_df has no filename column.\")\n",
        "\n",
        "        bm[\"file_base\"]   = bm[\"filename\"].astype(str).apply(lambda p: os.path.basename(p))\n",
        "        meta[\"file_base\"] = meta[\"filename\"].astype(str).apply(lambda p: os.path.basename(p))\n",
        "\n",
        "        meta_key = meta[[\"file_base\", meta_sex]].copy()\n",
        "        meta_key.columns = [\"file_base\", \"Sex\"]\n",
        "        meta_key = meta_key.dropna(subset=[\"file_base\"]).drop_duplicates(\"file_base\")\n",
        "\n",
        "        merged = bm.merge(meta_key, on=\"file_base\", how=\"left\").drop(columns=[\"file_base\"])\n",
        "\n",
        "    bm = merged\n",
        "\n",
        "# Normalize Sex values\n",
        "bm[GROUP_COL] = bm[GROUP_COL].apply(_norm_sex)\n",
        "\n",
        "# Keep only F/M for plotting (drop UNK)\n",
        "bm = bm[bm[GROUP_COL].isin([\"F\", \"M\"])].copy()\n",
        "if bm.empty:\n",
        "    raise RuntimeError(\"After merging/normalizing Sex, no rows with Sex in {F, M} were found.\")\n",
        "\n",
        "# -----------------------\n",
        "# Long format\n",
        "# -----------------------\n",
        "value_vars = [m for m in metrics if m in bm.columns]\n",
        "if not value_vars:\n",
        "    raise RuntimeError(\"None of the expected metric columns were found in Bandit100_metrics.\")\n",
        "\n",
        "id_vars = [c for c in [\"filename\", \"Mouse_ID\", \"Strain\", GROUP_COL] if c in bm.columns]\n",
        "long_df = bm.melt(id_vars=id_vars, value_vars=value_vars, var_name=\"metric\", value_name=\"value\")\n",
        "\n",
        "# consistent order\n",
        "groups = [g for g in [\"F\", \"M\"] if g in long_df[GROUP_COL].unique()]\n",
        "if len(groups) < 2:\n",
        "    raise RuntimeError(f\"Need both F and M present to compare; found: {groups}\")\n",
        "\n",
        "# -----------------------\n",
        "# Stats\n",
        "# -----------------------\n",
        "def welch_p(a, b):\n",
        "    a = pd.Series(a, dtype=float).dropna()\n",
        "    b = pd.Series(b, dtype=float).dropna()\n",
        "    if len(a) < 2 or len(b) < 2:\n",
        "        return np.nan\n",
        "    return float(pg.ttest(a, b, paired=False)[\"p-val\"].iat[0])\n",
        "\n",
        "# -----------------------\n",
        "# Plot UI\n",
        "# -----------------------\n",
        "out = widgets.Output()\n",
        "save_btn = widgets.Button(description=\"Save PDF\", button_style=\"success\")\n",
        "_last_fig = None\n",
        "\n",
        "def run_plots():\n",
        "    global _last_fig\n",
        "    with out:\n",
        "        clear_output()\n",
        "\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(8, 6), constrained_layout=True)\n",
        "        axes = axes.ravel()\n",
        "\n",
        "        for i, metric in enumerate(metrics):\n",
        "            ax = axes[i]\n",
        "            if metric not in value_vars:\n",
        "                ax.set_axis_off()\n",
        "                continue\n",
        "\n",
        "            dfm = long_df[long_df[\"metric\"] == metric].dropna(subset=[\"value\"])\n",
        "\n",
        "            pal = {g: COLOR_MAP[g] for g in groups}\n",
        "\n",
        "            sns.barplot(\n",
        "                data=dfm, x=GROUP_COL, y=\"value\",\n",
        "                order=groups, ci=None, alpha=0.6,\n",
        "                palette=pal, ax=ax\n",
        "            )\n",
        "            sns.stripplot(\n",
        "                data=dfm, x=GROUP_COL, y=\"value\",\n",
        "                order=groups,\n",
        "                color=\"white\", edgecolor=\"black\",\n",
        "                linewidth=1, size=6,\n",
        "                alpha=0.35, jitter=True, ax=ax\n",
        "            )\n",
        "\n",
        "            a = dfm.loc[dfm[GROUP_COL] == groups[0], \"value\"]\n",
        "            b = dfm.loc[dfm[GROUP_COL] == groups[1], \"value\"]\n",
        "            p = welch_p(a, b)\n",
        "            label = (\n",
        "                \"p<0.001\" if np.isfinite(p) and p < 0.001\n",
        "                else (f\"p={p:.3f}\" if np.isfinite(p) else \"p=NA\")\n",
        "            )\n",
        "\n",
        "            ax.set_title(\"\")\n",
        "            ax.set_xlabel(\"\")\n",
        "            ax.set_ylabel(metric, fontsize=12)\n",
        "            ax.text(0.5, 1.02, label, transform=ax.transAxes, ha=\"center\", va=\"bottom\")\n",
        "\n",
        "            sns.despine(ax=ax)\n",
        "\n",
        "        plt.show()\n",
        "        _last_fig = fig\n",
        "\n",
        "def save_plots(_=None):\n",
        "    if _last_fig is None:\n",
        "        with out:\n",
        "            print(\"Nothing to save yet.\")\n",
        "        return\n",
        "    fname = f\"metrics_grid_{int(time.time())}.pdf\"\n",
        "    _last_fig.savefig(fname, dpi=300, bbox_inches=\"tight\")\n",
        "    with out:\n",
        "        print(f\"Saved {fname}\")\n",
        "    if colab_files is not None:\n",
        "        colab_files.download(fname)\n",
        "\n",
        "save_btn.on_click(save_plots)\n",
        "\n",
        "display(save_btn)\n",
        "display(out)\n",
        "\n",
        "run_plots()\n"
      ],
      "metadata": {
        "id": "fhNui51xcBX0",
        "cellView": "form"
      },
      "id": "fhNui51xcBX0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Accuracy around switches\n",
        "\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Config ---\n",
        "TRIALS = 11\n",
        "COLOR_MAP = {\"F\": \"red\", \"M\": \"dodgerblue\"}\n",
        "\n",
        "# --- Preconditions ---\n",
        "if 'feds' not in globals() or not isinstance(feds, (list, tuple)) or len(feds) == 0:\n",
        "    raise RuntimeError(\"No FED3 sessions found in `feds`.\")\n",
        "if 'metadata_df' not in globals() or metadata_df is None or metadata_df.empty:\n",
        "    raise RuntimeError(\"metadata_df is missing/empty. Build it from the Key first.\")\n",
        "\n",
        "# --- Helpers ---\n",
        "def _basename(x): return os.path.basename(str(x))\n",
        "\n",
        "def _norm_sex(x):\n",
        "    s = str(x).strip().upper()\n",
        "    if s in {\"F\", \"FEMALE\", \"FEM\"}: return \"F\"\n",
        "    if s in {\"M\", \"MALE\"}: return \"M\"\n",
        "    return \"UNK\"\n",
        "\n",
        "def _find_col(df, name):\n",
        "    lc = {str(c).strip().lower(): c for c in df.columns}\n",
        "    return lc.get(name.lower(), None)\n",
        "\n",
        "def _extract_mouse_id_from_sess_name(name):\n",
        "\n",
        "    base = _basename(name)\n",
        "    base = re.sub(r\"\\.csv$\", \"\", base, flags=re.IGNORECASE)\n",
        "\n",
        "    # Strip trailing task/date: _Bandit80_YYYYMMDD, _FR1_YYYYMMDD, etc.\n",
        "    base = re.sub(r\"_(Bandit80|Bandit100|FR1|PR1)_\\d{8}$\", \"\", base, flags=re.IGNORECASE)\n",
        "    return base\n",
        "\n",
        "def _is_empty(x):\n",
        "    if x is None: return True\n",
        "    try:\n",
        "        return len(x) == 0\n",
        "    except Exception:\n",
        "        try:\n",
        "            return np.size(x) == 0\n",
        "        except Exception:\n",
        "            return True\n",
        "\n",
        "# --- Build Sex lookup from metadata_df ---\n",
        "meta = metadata_df.copy()\n",
        "meta_sex = _find_col(meta, \"Sex\")\n",
        "if meta_sex is None:\n",
        "    raise RuntimeError(\"metadata_df does not contain a 'Sex' column (case-insensitive).\")\n",
        "meta_mouse = _find_col(meta, \"Mouse_ID\")\n",
        "\n",
        "sex_lookup = {}\n",
        "\n",
        "# Prefer Mouse_ID mapping if present\n",
        "if meta_mouse is not None:\n",
        "    tmp = meta[[meta_mouse, meta_sex]].copy()\n",
        "    tmp.columns = [\"Mouse_ID\", \"Sex\"]\n",
        "    tmp[\"Mouse_ID\"] = tmp[\"Mouse_ID\"].astype(str).str.strip()\n",
        "    tmp[\"Sex\"] = tmp[\"Sex\"].apply(_norm_sex)\n",
        "    tmp = tmp.dropna(subset=[\"Mouse_ID\"]).drop_duplicates(\"Mouse_ID\")\n",
        "    sex_lookup = dict(zip(tmp[\"Mouse_ID\"], tmp[\"Sex\"]))\n",
        "\n",
        "# Fallback: if metadata_df has filename, build filename->sex map too\n",
        "file_sex_lookup = {}\n",
        "if \"filename\" in meta.columns:\n",
        "    tmp2 = meta[[\"filename\", meta_sex]].copy()\n",
        "    tmp2[\"file_base\"] = tmp2[\"filename\"].astype(str).apply(_basename)\n",
        "    tmp2[\"Sex\"] = tmp2[meta_sex].apply(_norm_sex)\n",
        "    tmp2 = tmp2.dropna(subset=[\"file_base\"]).drop_duplicates(\"file_base\")\n",
        "    file_sex_lookup = dict(zip(tmp2[\"file_base\"], tmp2[\"Sex\"]))\n",
        "\n",
        "# --- Build rev_df ---\n",
        "rows = []\n",
        "for i, sess in enumerate(feds):\n",
        "    sess_name = getattr(sess, \"name\", f\"session_{i}\")\n",
        "    base = _basename(sess_name)\n",
        "\n",
        "    # Get an ID from session filename and look up Sex\n",
        "    mouse_id = _extract_mouse_id_from_sess_name(base)\n",
        "    sex = sex_lookup.get(mouse_id, \"UNK\")\n",
        "\n",
        "    # fallback: try direct filename basename lookup (only if metadata has filename)\n",
        "    if sex == \"UNK\" and file_sex_lookup:\n",
        "        sex = file_sex_lookup.get(base, \"UNK\")\n",
        "\n",
        "    # compute peri-switch trials using your helper\n",
        "    try:\n",
        "        peh = f3b.reversal_peh(sess, (-TRIALS, TRIALS), return_avg=False)\n",
        "    except Exception as e:\n",
        "        print(f\"[skip] {base}: reversal_peh failed: {e}\")\n",
        "        continue\n",
        "\n",
        "    if _is_empty(peh) or sex not in {\"F\", \"M\"}:\n",
        "        continue\n",
        "\n",
        "    for tr in list(peh):\n",
        "        arr = np.asarray(tr).ravel()\n",
        "        for t, v in enumerate(arr):\n",
        "            rows.append({\n",
        "                \"Timepoint\": t - TRIALS + 1,\n",
        "                \"Value\": float(v) if np.isfinite(v) else np.nan,\n",
        "                \"Sex\": sex\n",
        "            })\n",
        "\n",
        "rev_df = pd.DataFrame(rows)\n",
        "rev_df = rev_df[np.isfinite(rev_df[\"Value\"])]\n",
        "rev_df = rev_df[rev_df[\"Timepoint\"] != 0]  # optional\n",
        "if rev_df.empty:\n",
        "    raise RuntimeError(\"No peri-switch data produced (after filtering to F/M).\")\n",
        "\n",
        "# --- Plot ---\n",
        "group_order = [g for g in [\"F\", \"M\"] if g in rev_df[\"Sex\"].unique()]\n",
        "palette = {g: COLOR_MAP[g] for g in group_order}\n",
        "\n",
        "plt.figure(figsize=(8, 5.2))\n",
        "ax = sns.lineplot(\n",
        "    data=rev_df.sort_values([\"Sex\", \"Timepoint\"]),\n",
        "    x=\"Timepoint\",\n",
        "    y=\"Value\",\n",
        "    hue=\"Sex\",\n",
        "    hue_order=group_order,\n",
        "    palette=palette,\n",
        "    estimator=\"mean\",\n",
        "    errorbar=\"se\",\n",
        "    n_boot=0,\n",
        "    lw=2\n",
        ")\n",
        "\n",
        "ax.axvline(x=0, color=\"darkgrey\", linestyle=\"--\", linewidth=1.25)\n",
        "ymin, ymax = ax.get_ylim()\n",
        "ax.text(0.5, ymin + 0.95*(ymax - ymin), \"Switch\", color=\"darkgrey\",\n",
        "        fontsize=12, ha=\"left\", va=\"top\")\n",
        "\n",
        "ax.set_xlabel(\"Trials from switch\")\n",
        "ax.set_ylabel(\"Accuracy (%)\")\n",
        "ax.set_title(\"\")\n",
        "ax.legend(title=\"\", frameon=False)\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VJSi78otlrKS",
        "cellView": "form"
      },
      "id": "VJSi78otlrKS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (Spyder)",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}